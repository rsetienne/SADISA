po <- list();
for(i in 1:3)
{
nn[[i]] <- list(nn1[[i]],nn2[[i]]);
po2[[i]][1] <- po1[[i]][1];
po[[i]] <- list(po1[[i]],po2[[i]]);
}
result <- SADISA_loglik(abund = nn,pars = po,model = c('pm','dl'), mult = 'both');
result2 <- SADISA_loglik(abund = nn1,pars = po1,model = c('pm','dl'), mult = 'ms');
result2 <- result2 + SADISA_loglik(abund = nn2,pars = po2,model = c('pm','dl'), mult = 'ms');
cat('\nThe difference is:',result - result2,'  ');
testthat::expect_equal(result,result2);
po1 <- fitresults$fit4.parsopt[[1]];
po1
fitresults$fit4.parsopt[[3]];
fitresults$fit4.parsopt[[11]];
devtools::load_all(".")
cat('\n\nTesting multiple-samples + multiple-guilds model (new):\n')
nn1 <- datasets$dset2.abunvec[[1]];
nn2 <- datasets$dset2.abunvec[[2]];
po1 <- fitresults$fit4.parsopt[[1]];
po2 <- fitresults$fit4.parsopt[[2]];
nn <- list();
po <- list();
for(i in 1:3)
{
nn[[i]] <- list(nn1[[i]],nn2[[i]]);
po2[[i]][1] <- po1[[i]][1];
po[[i]] <- list(po1[[i]],po2[[i]]);
}
result <- SADISA_loglik(abund = nn,pars = po,model = c('pm','dl'), mult = 'both');
result2 <- SADISA_loglik(abund = nn1,pars = po1,model = c('pm','dl'), mult = 'ms');
result2 <- result2 + SADISA_loglik(abund = nn2,pars = po2,model = c('pm','dl'), mult = 'ms');
cat('\nThe difference is:',result - result2,'  ');
testthat::expect_equal(result,result2);
datasets = NULL; rm(datasets);
fitresults = NULL; rm(fitresults);
utils::data('datasets', package = 'SADISA');
utils::data('fitresults', package = 'SADISA');
nn1 <- datasets$dset2.abunvec[[1]];
nn2 <- datasets$dset2.abunvec[[2]];
po1 <- fitresults$fit4.parsopt[[1]];
po2 <- fitresults$fit4.parsopt[[2]];
nn <- list();
po <- list();
for(i in 1:3)
{
nn[[i]] <- list(nn1[[i]],nn2[[i]]);
po2[[i]][1] <- po1[[i]][1];
po[[i]] <- list(po1[[i]],po2[[i]]);
}
nn
po
po
po1
po2
po
po
unlist(po)
po
po[[1]]
po[[1]][[1]]
po[[1]][[1]][[1]]
po[[1]][[1]][[1]][[1]]
nn
nn[[1]]
nn[[1]][[1]]
ff <- NULL
ff[[1]] = c(2,1,0)
ff
ff[[1]][[1]] = c(2,1,0)
ff[[1]][[2]] = c(2,1,0)
ff[[2]] = c(2,1,0)
ff
library(SADISA)
library(lme3)
library(lme4)
install.packages("lme4", lib="C:/Program Files/R/R-devel/library")
library(lme4)
install.packages("minqa", lib="C:/Program Files/R/R-devel/library")
library(lme4)
install.packages("nloptr", lib="C:/Program Files/R/R-devel/library")
library(lme4)
m1 <- lmer(Informed.liking ~ Gender*Information +(1|Consumer), data=ham)
library(lmerTest)
install.packages("lmerTest", lib="C:/Program Files/R/R-devel/library")
library(lmerTest)
install.packages("Hmisc", lib="C:/Program Files/R/R-devel/library")
library(lmerTest)
install.packages("acepack", lib="C:/Program Files/R/R-devel/library")
library(lmerTest)
install.packages("base64enc", lib="C:/Program Files/R/R-devel/library")
library(lmerTest)
m1 <- lmer(Informed.liking ~ Gender*Information +(1|Consumer), data=ham)
difflsmeans(m1, test.effs="Gender:Information")
amh
ham
header(ham)
head(ham)
difflsmeans(m1)
m <- lmer(Coloursaturation ~ TVset*Picture + (1|Assessor), data=TVbo)
plot(difflsmeans(m, test.effs="TVset"))
m <- lmer(Coloursaturation ~ TVset*Picture + (1|Assessor), data=TVbo)
plot(difflsmeans(m, test.effs="Picture"))
m <- lmer(Coloursaturation ~ TVset*Picture + (1|Assessor), data=TVbo)
plot(difflsmeans(m, test.effs="TVset*Picture"))
m <- lmer(Coloursaturation ~ TVset*Picture + (1|Assessor), data=TVbo)
plot(difflsmeans(m, test.effs="TVset*Picture"))
m <- lmer(Coloursaturation ~ TVset*Picture + (1|Assessor), data=TVbo)
plot(difflsmeans(m, test.effs="TVset"))
library(SADISA)
library(R.utils)
v <- read.table("d:/data/ms/New_corrected_species_list_R.txt", header = T)
selected <- c(3, 4) #central america
initial_parameters <- c(10, 1000)
# prep the data
animal_guild <- subset(v, v$Dispersal == "a")
wind_guild <- subset(v, v$Dispersal == "w")
animal_guild <- animal_guild[,selected]
wind_guild <- wind_guild[,selected]
# calculate the row sums, if these are zero, exclude that line
a <- rowSums(animal_guild)
animal_guild <- animal_guild[which(a > 0),]
# calculate the row sums, if these are zero, exclude that line
a <- rowSums(wind_guild)
wind_guild <- wind_guild[which(a > 0),]
# set up van de verschillende lijsten
all_sites <- list()
init_pars <- list()
parlbl <- list()
for(cnt in 1:length(selected)) {
b1 <- animal_guild[,cnt]
b2 <- wind_guild[,cnt]
vv1 <- as.numeric(unlist(b1))
vv2 <- as.numeric(unlist(b2))
guilds <- list(vv1, vv2)
all_sites[[cnt]] <- guilds
int_par <- list( c(initial_parameters[1], initial_parameters[2]),
c(initial_parameters[1], initial_parameters[2]))
init_pars[[cnt]] <- int_par
# labelpars table is een LIST
lbl_par <- list(c(2, 1), c(2, 1))
if(cnt == 1) lbl_par <- list(c(1,1), c(2,1))
parlbl[[cnt]] <- lbl_par
}
all_sites
initpars
init_pars
parlbl
# nu voor een enkele site, met 2 guilds:
selected <- 22
animal_guild <- subset(v, v$Dispersal == "a")
wind_guild <- subset(v, v$Dispersal == "w")
animal_guild <- animal_guild[,selected]
wind_guild <- wind_guild[,selected]
animal_guild <- animal_guild[which(animal_guild > 0)]
wind_guild <- wind_guild[which(wind_guild > 0)]
# set up van de verschillende lijsten
all_sites <- list()
all_sites[[1]] <- animal_guild
all_sites[[2]] <- wind_guild
# Label_pars een LIST
parlbl <- list()
parlbl[[1]] <- c(1, 1)
parlbl[[2]] <- c(2, 1)
parlbl
init_pars <- list()
init_pars[[1]] <- c(1000, 10)
init_pars[[2]] <- c(1000, 10)
init_pars
all_sites
parlbl2 <- matrix(c(1,1,2,1), nrow = 2, ncol =2, byrow = T)
parlbl2
library(sls)
load('d:/data/ms/COMMUNITY MATRIX')
load('d:/data/ms/COMMUNITY MATRIX.RData')
load('d:/data/ms/COMMUNITY_MATRIX.RData')
ls()
COMMUNITY_MATRIX<-t(COMMUNITY_MATRIX[,-1])
#Set the model to work with.
model <- c('pm','dl')
#Set vectors for theta and I with values to evaluate.
theta_values<-10^seq(0,2,0.5)
I_values<-10^seq(0,2.5,0.5)
COMMUNITY_MATRIX
library(SADISA
)
library(SADISA)
install.packages("D:/data/Ms/SADISA/SADISA_1.1.tar.gz", repos = NULL, type = "source")
install.packages("rootSolve")
install.packages("D:/data/Ms/SADISA/SADISA_1.1.tar.gz", repos = NULL, type = "source")
library(rootSolve)
devtools::load_all(".")
#' @title Performs maximum likelihood parameter estimation for requested model
#' @description Computes maximum loglikelihood and corresponding parameters for the requested model using the independent-species approach.
#' For optimization it uses various auxiliary functions in the DDD package.
#' @param abund abundance vector or a list of abundance vectors.
#' When a list is provided and mult = 'mg' (the default), it is assumed that the different vectors
#' apply to different guilds. When mult = 'ms' then the different vectors apply to multiple samples.
#' from the same metacommunity. In this case the vectors should have equal lengths and may contain
#' zeros because there may be species that occur in multiple samples and species that do not occur
#' in some of the samples.
#' @param initpars a vector of initial values of the parameters to be optimized and fixed. See \code{labelpars}
#' for more explanation.
#' @param idpars a vector stating whether the parameters in \code{initpars} should be optimized (1) or
#' remain fixed (0).
#' @param labelpars a vector, a list of vectors or a list of lists of vectors indicating the labels
#' integers (starting at 1) of the parameters to be optimized and fixed. These integers correspond to
#' the position in \code{initpars} and \code{idpars}. The order of the labels in
#' the vector/list is first the metacommunity parameters (theta), then the dispersal parameters (I).
#' See the example and the vignette for more explanation.
#' @param model the chosen combination of metacommunity model and local community model
#' as a vector, e.g. c('pm','dl') for a model with point mutation in the metacommunity and
#' dispersal limitation.
#' The choices for the metacommunity model are: 'pm' (point mutation), 'rf' (random fission),
#' 'pr' (protracted speciation), 'dd' (density-dependence).
#' The choices for the local community model are: 'dl' (dispersal limitation), 'dd' (density-dependence).
#' @param mult When set to 'single' (the default), the loglikelihood for a single sample and single guild
#' is computed. When set to 'mg', the loglikelihood for multiple guilds is computed.
#' When set to 'ms' the loglikelihood for multiple samples from the same metacommunity is computed.
#' @details Not all combinations of metacommunity model and local community model have been implemented yet.
#' because this requires checking for numerical stability of the integration. The currently available model combinations are, for a single sample, c('pm','dl'), c('pm','rf'), c('dd','dl'),
#' c('pr','dl'), c('pm','dd'), and for multiple samples, c('pm','dl').
#' @param tol a vector containing three numbers for the relative tolerance in the parameters, the relative tolerance in the function, and the absolute tolerance in the parameters.
#' @param maxiter sets the maximum number of iterations
#' @param optimmethod sets the optimization method to be used, either subplex (default) or an alternative implementation of simplex.
#' @keywords model species-abundance-distribution
#' @references Haegeman, B. & R.S. Etienne (2017). A general sampling formula for community structure data. Methods in Ecology & Evolution 8: 1506-1519. doi: 10.1111/2041-210X.12807
#' @examples
#' utils::data(datasets);
#' utils::data(fitresults);
#' result <- SADISA_ML(
#'    abund = datasets$dset1.abunvec[[1]],
#'    initparsopt = fitresults$fit1a.parsopt[[1]],
#'    parsfix = NULL,
#'    labelpars = c(1,2),
#'    model = c('pm','dl'),
#'    tol = c(1E-1, 1E-1, 1E-1)
#'    );
#' # Note that tolerances should be set much lower than 1E-1 to get the best results.
#' @export
#'
SADISA_ML <- function(
abund,
initpars,
idpars,
labelpars,
model = c('pm','dl'),
mult = 'single',
tol = c(1E-6, 1E-6, 1E-6),
maxiter = 1000 * round((1.25)^length(initparsopt)),
optimmethod = 'subplex'
)
{
if(mult != 'single' && !is.list(labelpars))
{
stop('The labels of the parameters should be in a list when there are multiple samples or guilds.')
}
initpars <- initpars/(1 + initpars);
if(!is.null(which(idpars == 1)))
{
trparsopt <- initpars[which(idpars == 1)];
} else
{
trparsopt <- NULL;
stop('You are not optimizing anything.')
}
if(!is.null(which(idpars == 0)))
{
trparsfix <- initpars[which(idpars == 0)];
} else
{
trparsfix <- NULL;
}
trparsopt[which(trparsopt == Inf, arr.ind = TRUE)] <- 1;
trparsfix[which(trparsfix == Inf, arr.ind = TRUE)] <- 1;
initloglik <- SADISA_loglik_choosepar(trparsopt = trparsopt,trparsfix = trparsfix,labelpars = labelpars,abund = abund,model = model,mult = mult);
cat("The loglikelihood for the initial parameter values is ",initloglik,".\n",sep = '');
utils::flush.console();
if(initloglik == -Inf)
{
cat("The initial parameter values have a likelihood that is equal to 0 or below machine precision. Try again with different initial values.\n");
out <- NA;
return(out);
} else {
optimpars <- c(tol,maxiter);
out <- DDD::optimizer(optimmethod = optimmethod,optimpars = optimpars,fun = SADISA_loglik_choosepar,trparsopt = trparsopt,trparsfix = trparsfix,labelpars = labelpars,abund = abund,model = model,mult = mult);
}
if(out$conv != 0)
{
cat("Optimization has not converged. Try again with different initial values.\n");
out <- NA;
return(out);
}
MLtrpars <- as.numeric(unlist(out$par));
MLpars <- MLtrpars/(1 - MLtrpars);
ML <- as.numeric(unlist(out$fvalues));
pars <- make_list_of_pars(MLpars,parsfix,labelpars)
out <- list(pars = pars, loglik = ML, conv = unlist(out$conv));
cat('\nParameters after likelihood maximization:\n');
print(pars);
cat('\nMaximum loglikelihood:\n',ML,'\n\n');
return(out);
}
SADISA_loglik_choosepar <- function(trparsopt,trparsfix,labelpars,abund,model,mult)
{
if(!is.list(abund))
{
abund <- list(abund);
}
trpars1 <- make_list_of_pars(trparsopt,trparsfix,labelpars)
unlisttrpars1 <- unlist(trpars1);
if(max(unlisttrpars1) > 1 || min(unlisttrpars1) < 0)
{
loglik = -Inf;
return(loglik);
} else {
pars <- untransform_list_of_pars(trpars1)
loglik <- SADISA_loglik(abund = abund, pars = pars, model = model, mult = mult);
if(is.nan(loglik) || is.na(loglik))
{
cat("There are parameter values which cause numerical problems.\n")
loglik <- -Inf;
return(loglik);
}
}
return(loglik);
}
make_list_of_pars <- function(trparsopt,trparsfix,labelpars)
{
trpars1 <- labelpars;
if(!is.list(trpars1))
{
if(length(trparsopt > 0))
{
for(lb in 1:length(trparsopt))
{
sel <- which(labelpars == lb);
if(!is.null(sel))
{
trpars1[sel] <- trparsopt[lb];
}
}
}
if(length(trparsfix > 0))
{
for(lb in (length(trparsopt) + 1):(length(trparsopt) + length(trparsfix)))
{
sel <- which(labelpars == lb);
if(!is.null(sel))
{
trpars1[sel] <- trparsfix[lb - length(trparsopt)];
}
}
}
} else if(!is.list(trpars1[[1]]))
{
for(i in 1:length(trpars1))
{
if(length(trparsopt) > 0)
{
for(lb in 1:length(trparsopt))
{
sel <- which(labelpars[[i]] == lb);
if(!is.null(sel))
{
trpars1[[i]][sel] <- trparsopt[lb];
}
}
}
if(length(trparsfix > 0))
{
for(lb in (length(trparsopt) + 1):(length(trparsopt) + length(trparsfix)))
{
sel <- which(labelpars[[i]] == lb);
if(!is.null(sel))
{
trpars1[[i]][sel] <- trparsfix[lb - length(trparsopt)];
}
}
}
}
} else
{
dim1 <- length(trpars1);
dim2 <- length(trpars1[[1]]);
for(i in 1:dim1)
{
for(j in 1:dim2)
{
if(length(trparsopt) > 0)
{
for(lb in 1:length(trparsopt))
{
sel <- which(labelpars[[i]][[j]] == lb);
if(!is.null(sel))
{
trpars1[[i]][[j]][sel] <- trparsopt[lb];
}
}
}
if(length(trparsfix) > 0)
{
for(lb in (length(trparsopt) + 1):(length(trparsopt) + length(trparsfix)))
{
sel <- which(labelpars[[i]][[j]] == lb);
if(!is.null(sel))
{
trpars1[[i]][[j]][sel] <- trparsfix[lb - length(trparsopt)];
}
}
}
}
}
}
return(trpars1)
}
untransform_list_of_pars <- function(trpars1)
{
pars <- trpars1;
if(!is.list(trpars1))
{
pars <- trpars1/(1 - trpars1);
} else if(!is.list(trpars1[[1]]))
{
for(i in 1:length(trpars1))
{
pars[[i]] <- trpars1[[i]]/(1 - trpars1[[i]]);
}
} else
{
dim1 <- length(trpars1);
dim2 <- length(trpars1[[1]]);
for(i in 1:dim1)
{
for(j in 1:dim2)
{
pars[[i]][[j]] <- trpars1[[i]][[j]]/(1 - trpars1[[i]][[j]]);
}
}
}
return(pars)
}
library("SADISA", lib.loc="~/R/win-library/3.6")
detach("package:SADISA", unload=TRUE)
devtools::load_all(".")
remove.packages("SADISA", lib="~/R/win-library/3.6")
SADISA_ML
exp(-3.5)
log10(exp(-3.5))
load('d:/data/ms/DDD/biastest1b-4241-simplex.RData')
rn(list = ls())
rm(list = ls())
load('d:/data/ms/DDD/biastest1b-4241-simplex.RData')
restot
restot[[1]]
restot[[2]]
restot[[3]]
restot[[4]]
restot[[5]]
restot[[10]]
restot[[6]]
restot[[7]]
restot[[8]]
restot[[9]]
source('d:/data/tex/LDG/LDG.R')
source('d:/data/tex/LDG/LDG2.R')
install.packages("latex2exp", lib="C:/Program Files/R/R-devel/library")
source('d:/data/tex/LDG/LDG2.R')
setwd("d:/data/ms/DDD")
library(ape) ; library(DDD)
# Load data
load("sample_trees_simDD-4241.RData")
# decalre dd_ML arguments
initpars <-  c(60, 0.8, 0.4, 40)
methode = 'ode45'
#methode = 'analytical'
optimmethod = 'subplex'
#optimmethod = 'simplex'
outerror = data.frame(lambda = -1,mu = -1,K = -1, loglik = -1, df = -1, conv = -1)
results = NULL
seq_along(trees)
i = 1
mc <- names(trees)[i]
print(paste("Optimizing on tree",mc))
# fit DD
results_mc = try(dd_ML(as.numeric(branching.times(trees[[i]])), initparsopt = initpars[2:4]+1E-6, cond = 1, tol = rep(1E-6,3),
methode = methode, optimmethod = optimmethod))
if(!is.data.frame(results_mc)) { results_mc = outerror }
# Assemble results
results_mc <- cbind(results_mc, "mc" = mc)
results <- rbind(results,results_mc)
load("sample_trees_simDD-4241.RData")
setwd("d:/data/ms/DDD/")
load("sample_trees_simDD-4241.RData")
load("d:/data/ms/DDD/sample_trees_simDD-4241.RData")
load("sample_trees_test.RData")
mc <- names(trees)[i]
print(paste("Optimizing on tree",mc))
# fit DD
results_mc = try(dd_ML(as.numeric(branching.times(trees[[i]])), initparsopt = initpars[2:4]+1E-6, cond = 1, tol = rep(1E-6,3),
methode = methode, optimmethod = optimmethod))
optimmethod = 'simplex'
mc <- names(trees)[i]
print(paste("Optimizing on tree",mc))
# fit DD
results_mc = try(dd_ML(as.numeric(branching.times(trees[[i]])), initparsopt = initpars[2:4]+1E-6, cond = 1, tol = rep(1E-6,3),
methode = methode, optimmethod = optimmethod))
if(!is.data.frame(results_mc)) { results_mc = outerror }
# Assemble results
results_mc <- cbind(results_mc, "mc" = mc)
results <- rbind(results,results_mc)
